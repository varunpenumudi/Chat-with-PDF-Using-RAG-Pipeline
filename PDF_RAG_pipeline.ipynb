{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPW78jqP9bLuxEqDo6n1MJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunpenumudi/Chat-with-PDF-Using-RAG-Pipeline/blob/main/PDF_RAG_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Necessary Packages/Dependencies Installation"
      ],
      "metadata": {
        "id": "8_a21xCuU5Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_huggingface langchain_chroma langchain-groq\n",
        "!pip  install langchain_community pypdf pymupdf pytesseract"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4OGQBUI9JsuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install libtesseract-dev"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RmBj5oWPMhzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "hS1GGYadTm9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# Imports for working with data\n",
        "from langchain_community.document_loaders import PyPDFLoader        # Extract PDF\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter # Split PDF into chunks\n",
        "from langchain_core.documents import Document                       # Convert To Langchain Document\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings  # Embedding the data\n",
        "from langchain_chroma import Chroma                                 # Vector Store\n",
        "\n",
        "# Import LLM\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Retreival chain to create the pipeline\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "# Imports for ocr of images\n",
        "import fitz                            # PyMuPDF\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from pytesseract import pytesseract"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RSIfnRBKJi0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Data from PDF and Split Text"
      ],
      "metadata": {
        "id": "FsD4XrXyUUac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load pdf\n",
        "\n",
        "file_path = \"example.pdf\"\n",
        "\n",
        "loader = PyPDFLoader(file_path)\n",
        "docs = loader.load()\n",
        "\n",
        "print(len(docs))"
      ],
      "metadata": {
        "id": "K_SZX5__UUzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee46c2f-7ed1-4793-ef1e-556ef9f7a7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to extract images contents from the PDF\n",
        "\n",
        "def extract_images_from_pdf(pdf_path):\n",
        "    # Open the PDF file\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "    all_images = []\n",
        "\n",
        "    # Iterate through all the pages\n",
        "    for page_num in range(len(pdf_document)):\n",
        "        page = pdf_document.load_page(page_num)\n",
        "\n",
        "        # Get all images on the current page\n",
        "        image_list = page.get_images(full=True)\n",
        "\n",
        "        # If there are images on this page\n",
        "        if image_list:\n",
        "            print(f\"[+] Found {len(image_list)} image(s) on page {page_num + 1}\")\n",
        "\n",
        "            # Extract each image\n",
        "            for img_index, img in enumerate(image_list):\n",
        "                xref = img[0]  # Image reference\n",
        "                base_image = pdf_document.extract_image(xref)  # Extract the image\n",
        "\n",
        "                # Get image bytes\n",
        "                image_bytes = base_image[\"image\"]\n",
        "\n",
        "                # Convert bytes to image using PIL\n",
        "                image = Image.open(BytesIO(image_bytes))\n",
        "\n",
        "                # Display the image\n",
        "                all_images.append(image)\n",
        "\n",
        "    pdf_document.close()\n",
        "    return all_images\n",
        "\n",
        "def images_to_text(imgs):\n",
        "    texts = []\n",
        "    for img in imgs:\n",
        "        text = pytesseract.image_to_string(img)\n",
        "        texts.append(text)\n",
        "    return texts\n",
        "\n",
        "\n",
        "image_text_docs = [Document(page_content=text, metadata={\"file_name\": file_path}) for text in texts]\n",
        "docs.extend(image_text_docs)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wU0xA2Q_KmqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into Chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# Store splits in vector DB\n",
        "# using HuggingFace Embeddings\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=HuggingFaceEmbeddings())\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "peKinnl1Kgs2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the Groq LLM"
      ],
      "metadata": {
        "id": "9kUMESK2Xbg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Your API Key for Groq LLM from this url:\n",
        "<br>\n",
        "https://console.groq.com/keys"
      ],
      "metadata": {
        "id": "SHKO6T99Z-HT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.getenv(\"GROQ_API_KEY\") is None:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API Key: \")\n",
        "\n",
        "llm = ChatGroq(model=\"llama3-8b-8192\")\n",
        "\n",
        "system_prompt = (\n",
        "    \"\"\"\n",
        "    You are an advanced language model equipped with a Retrieval-Augmented Generation (RAG) pipeline. Your task is to assist in answering user queries related to documents containing semi-structured data such as text, tables, and charts.\n",
        "\n",
        "    Context: Below is the relevant context retrieved from the document based on the user's query. This context includes text, tables, or other data extracted from the PDF.\n",
        "\n",
        "    {context}\n",
        "\n",
        "    Please use the context provided to answer the user's query accurately and thoroughly. Ensure that the response incorporates specific details from the retrieved context, especially when dealing with factual or numerical information.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)"
      ],
      "metadata": {
        "id": "M1mclr4uXPks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the Chain/Pipeline"
      ],
      "metadata": {
        "id": "K_uKQlYHGm1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "def get_resp(question):\n",
        "    results = rag_chain.invoke({\"input\": question})\n",
        "    resp = results['answer'].split(\"\\n\")\n",
        "    pprint(resp)"
      ],
      "metadata": {
        "id": "vvewLfx5E1of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_resp(\"compare us gdp in 2011 and 2015?\")"
      ],
      "metadata": {
        "id": "PMqKfEqRGhz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_resp(\"What is Unemployement rates?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5usUzfexKIaJ",
        "outputId": "89d0d379-8a42-43e8-cebd-e0042b0be4a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['According to the provided context, the unemployment rate in 2013 varies by '\n",
            " 'educational attainment. Here are the specific unemployment rates mentioned:',\n",
            " '',\n",
            " '* All workers: 6.1%',\n",
            " '',\n",
            " 'Additionally, the context provides unemployment rates for different '\n",
            " 'educational attainment levels:',\n",
            " '',\n",
            " '* Doctoral degree: (no specific rate mentioned)',\n",
            " '* Professional degree: (no specific rate mentioned)',\n",
            " \"* Master's degree: (no specific rate mentioned)\",\n",
            " \"* Bachelor's degree: (no specific rate mentioned)\",\n",
            " \"* Associate's degree: (no specific rate mentioned)\",\n",
            " '* Some college, no degree: (no specific rate mentioned)',\n",
            " '* High school diploma: (no specific rate mentioned)',\n",
            " '* Less than a high school diploma: (no specific rate mentioned)',\n",
            " '',\n",
            " 'Please note that the context only provides unemployment rates for all '\n",
            " 'workers and by educational attainment, but not for specific demographics '\n",
            " 'such as men and women.']\n"
          ]
        }
      ]
    }
  ]
}